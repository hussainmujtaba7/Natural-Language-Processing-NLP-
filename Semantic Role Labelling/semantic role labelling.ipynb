{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:20.539556Z","iopub.execute_input":"2023-02-03T00:48:20.539958Z","iopub.status.idle":"2023-02-03T00:48:30.423741Z","shell.execute_reply.started":"2023-02-03T00:48:20.539927Z","shell.execute_reply":"2023-02-03T00:48:30.422382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom zipfile import ZipFile\nfrom sklearn.model_selection import train_test_split\nfrom typing import Dict\nimport torch\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.nn.functional as F\nfrom sklearn.metrics import f1_score\nfrom operator import itemgetter\nfrom sklearn.metrics import precision_score\nimport pickle\nimport time\nfrom tqdm import tqdm\n\nfrom transformers import AutoModel\nfrom transformers import AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:30.426871Z","iopub.execute_input":"2023-02-03T00:48:30.427266Z","iopub.status.idle":"2023-02-03T00:48:30.435353Z","shell.execute_reply.started":"2023-02-03T00:48:30.427227Z","shell.execute_reply":"2023-02-03T00:48:30.433652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nlanguage_model_name = \"xlm-roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(language_model_name)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:30.437147Z","iopub.execute_input":"2023-02-03T00:48:30.437884Z","iopub.status.idle":"2023-02-03T00:48:34.484936Z","shell.execute_reply.started":"2023-02-03T00:48:30.437847Z","shell.execute_reply":"2023-02-03T00:48:34.483868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utility functions\ndef separate_predicates(predicates_list):\n  index_predicate=[]\n  for i,j in enumerate(predicates_list):\n    if j is not '_':\n      index_predicate.append(i) \n  return index_predicate  \n\ndef get_dict(d,k):\n  return d.get(str(k))\n\ndef role_label(lis):\n  return [label_to_id[i] for i in lis]\n\ndef role_pos(lis):\n    return [pos_to_id[i] for i in lis]\n\ndef add_predicate(lis,predicates,k):\n  predicate_sense=predicates[k]\n  if predicate_sense in label_to_id.keys():\n      lis[k]=label_to_id[predicate_sense]\n  return lis\n\ndef id_to_onehotencode(k,length):\n    temp=torch.zeros(length)\n    temp[k]=1\n    return temp\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:34.486638Z","iopub.execute_input":"2023-02-03T00:48:34.487516Z","iopub.status.idle":"2023-02-03T00:48:34.496929Z","shell.execute_reply.started":"2023-02-03T00:48:34.487473Z","shell.execute_reply":"2023-02-03T00:48:34.495844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TranDataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n        self.text= df[['lemmas']].values.tolist()\n        self.labels=df[['roles']].values.tolist()  \n        self.predicate_loc=df.index_predicate.values.tolist()\n        self.pos_tag=df[['pos_tags']].values.tolist() \n        \n    def __len__(self):\n        return len(self.text)\n  \n    def __getitem__(self,idx):\n        return self.text[idx],self.labels[idx],self.predicate_loc[idx],self.pos_tag[idx]\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:34.500051Z","iopub.execute_input":"2023-02-03T00:48:34.500494Z","iopub.status.idle":"2023-02-03T00:48:34.512873Z","shell.execute_reply.started":"2023-02-03T00:48:34.500456Z","shell.execute_reply":"2023-02-03T00:48:34.511959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preprocess inputs\n# use_predicate : True for using predicate sense information while training\n# use_predicate : False for using predicate location information while training\nuse_predicate=False\ndef collate_fn(batch):\n    #get input_ids and attenstion mask for transformer network\n    batch_out = tokenizer(\n        [sentence[0][0] for sentence in batch],\n        return_tensors=\"pt\",\n        padding=True,\n        is_split_into_words=True,\n    )\n    # modify labels,predicate_location,pos_tags according to output from tokenizer\n    labels = []\n    predicate_loc = []\n    pos_tag = []\n    srl_tags = [sentence[1][0] for sentence in batch]\n    predicate_tag=[sentence[2] for sentence in batch]\n    pos =[sentence[3][0] for sentence in batch]\n    for i, label in enumerate(zip(srl_tags,predicate_tag,pos)):\n        #convert predictae position to onehot_encode \n        predicate_onehot=id_to_onehotencode(label[1],len(label[0]))\n      # obtains the word_ids of the i-th sentence\n        word_ids = batch_out.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        predicate_ids = []\n        pos_ids = []\n        for word_idx in word_ids:\n        # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n        # ignored in the loss function.\n            if word_idx is None:\n                pos_ids.append(0)\n                label_ids.append(-100)\n                predicate_ids.append(0)\n        # We set the label for the first token of each word.\n            elif word_idx != previous_word_idx:\n                pos_ids.append(label[2][word_idx])\n                label_ids.append(label[0][word_idx])\n                #use predicate sense if true,else just use location information\n                if use_predicate:\n                    predicate_ids.append(predicate_onehot[word_idx]*label[0][word_idx])\n                else:\n                    predicate_ids.append(predicate_onehot[word_idx])\n        # For the other tokens in a word, we set the label same to as above\n            else:\n                pos_ids.append(label[2][word_idx])\n                label_ids.append(label[0][word_idx])\n                #use predicate sense if true,else just use location information\n                if use_predicate:\n                    predicate_ids.append(predicate_onehot[word_idx]*label[0][word_idx])\n                else:\n                    predicate_ids.append(predicate_onehot[word_idx])\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n        predicate_loc.append(predicate_ids)\n        pos_tag.append(pos_ids)\n    \n    # pad the labels with -100\n    batch_max_length = len(max(labels, key=len))\n    labels = [l + ([-100] * abs(batch_max_length - len(l))) for l in labels]\n    pos_tag = [l + ([0] * abs(batch_max_length - len(l))) for l in pos_tag]\n    batch_out[\"labels\"] = torch.as_tensor(labels)\n    batch_out[\"predicate_loc\"] = torch.as_tensor(predicate_loc)[:,:,None]\n    batch_out[\"pos_tag\"] = F.one_hot(torch.as_tensor(pos_tag),18)\n    \n    return batch_out","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:34.514534Z","iopub.execute_input":"2023-02-03T00:48:34.515181Z","iopub.status.idle":"2023-02-03T00:48:34.530798Z","shell.execute_reply.started":"2023-02-03T00:48:34.515084Z","shell.execute_reply":"2023-02-03T00:48:34.529874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_json('/kaggle/input/data-srl-nlp-modified/data_hw2/data_hw2/EN/train.json').transpose(copy=True)\ndata[\"index_predicate\"]=data['predicates'].apply(lambda x:separate_predicates(x))\ndata=data.explode('index_predicate')\ndata.dropna(inplace=True)\ndata['roles'] = data.apply(lambda x: get_dict(x['roles'], x['index_predicate']), axis=1)\ndata.dropna(inplace=True)\nlabel_to_id = {n: i for i, n in enumerate(data.explode('roles').dropna()['roles'].unique())}\npredicate_to_id={n: i+len(label_to_id)-1 for i, n in enumerate(data.explode('predicates').dropna()['predicates'].unique()) if '_' !=n}\nlabel_to_id.update(predicate_to_id)\nid_to_label = {i: n for n, i in label_to_id.items()}\npos_to_id = {n: i+1 for i, n in enumerate(data.explode('pos_tags')['pos_tags'].unique())}\ndata['roles']=data.roles.apply(lambda x: role_label(x))\ndata['roles'] = data.apply(lambda x: add_predicate(x['roles'],x['predicates'], x['index_predicate']), axis=1)\ndata['pos_tags']=data.pos_tags.apply(lambda x: role_pos(x))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:34.533307Z","iopub.execute_input":"2023-02-03T00:48:34.533582Z","iopub.status.idle":"2023-02-03T00:48:37.992243Z","shell.execute_reply.started":"2023-02-03T00:48:34.533546Z","shell.execute_reply":"2023-02-03T00:48:37.991214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_to_id","metadata":{"execution":{"iopub.status.busy":"2023-02-03T02:08:00.412005Z","iopub.execute_input":"2023-02-03T02:08:00.412424Z","iopub.status.idle":"2023-02-03T02:08:00.420014Z","shell.execute_reply.started":"2023-02-03T02:08:00.412390Z","shell.execute_reply":"2023-02-03T02:08:00.418967Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"{'NOUN': 1,\n 'ADV': 2,\n 'VERB': 3,\n 'SCONJ': 4,\n 'DET': 5,\n 'ADJ': 6,\n 'ADP': 7,\n 'PUNCT': 8,\n 'PROPN': 9,\n 'PART': 10,\n 'NUM': 11,\n 'CCONJ': 12,\n 'AUX': 13,\n 'PRON': 14,\n 'SYM': 15,\n 'X': 16,\n 'INTJ': 17}"},"metadata":{}}]},{"cell_type":"code","source":"label_to_id","metadata":{"execution":{"iopub.status.busy":"2023-02-03T02:08:00.422038Z","iopub.execute_input":"2023-02-03T02:08:00.422645Z","iopub.status.idle":"2023-02-03T02:08:00.441423Z","shell.execute_reply.started":"2023-02-03T02:08:00.422599Z","shell.execute_reply":"2023-02-03T02:08:00.440557Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"{'agent': 0,\n '_': 1,\n 'theme': 2,\n 'beneficiary': 3,\n 'patient': 4,\n 'topic': 5,\n 'goal': 6,\n 'recipient': 7,\n 'co-theme': 8,\n 'result': 9,\n 'stimulus': 10,\n 'experiencer': 11,\n 'destination': 12,\n 'value': 13,\n 'attribute': 14,\n 'location': 15,\n 'source': 16,\n 'cause': 17,\n 'co-agent': 18,\n 'time': 19,\n 'co-patient': 20,\n 'product': 21,\n 'purpose': 22,\n 'instrument': 23,\n 'extent': 24,\n 'asset': 25,\n 'material': 26,\n 'ASK_REQUEST': 27,\n 'BENEFIT_EXPLOIT': 28,\n 'PLAN_SCHEDULE': 29,\n 'CARRY-OUT-ACTION': 30,\n 'ESTABLISH': 31,\n 'SIMPLIFY': 32,\n 'PROPOSE': 33,\n 'TAKE-INTO-ACCOUNT_CONSIDER': 34,\n 'BEGIN': 35,\n 'CIRCULATE_SPREAD_DISTRIBUTE': 36,\n 'REFER': 37,\n 'SHOW': 38,\n 'PRECLUDE_FORBID_EXPEL': 39,\n 'VIOLATE': 40,\n 'VERIFY': 41,\n 'CAUSE-SMT': 42,\n 'ABSTAIN_AVOID_REFRAIN': 43,\n 'TRANSMIT': 44,\n 'SEE': 45,\n 'SUMMON': 46,\n 'GUARANTEE_ENSURE_PROMISE': 47,\n 'RECEIVE': 48,\n 'INCREASE_ENLARGE_MULTIPLY': 49,\n 'DECREE_DECLARE': 50,\n 'PAY': 51,\n 'CAUSE-MENTAL-STATE': 52,\n 'CAGE_IMPRISON': 53,\n 'HURT_HARM_ACHE': 54,\n 'MOVE-BACK': 55,\n 'EXIST_LIVE': 56,\n 'CALCULATE_ESTIMATE': 57,\n 'ATTRACT_SUCK': 58,\n 'EXIST-WITH-FEATURE': 59,\n 'INFORM': 60,\n 'EXPLAIN': 61,\n 'SPEAK': 62,\n 'SEEM': 63,\n 'MISS_OMIT_LACK': 64,\n 'DECIDE_DETERMINE': 65,\n 'ASSIGN-SMT-TO-SMN': 66,\n 'FOLLOW_SUPPORT_SPONSOR_FUND': 67,\n 'MOVE-ONESELF': 68,\n 'WORSEN': 69,\n 'AMELIORATE': 70,\n 'AGREE_ACCEPT': 71,\n 'MOVE-SOMETHING': 72,\n 'PUT_APPLY_PLACE_PAVE': 73,\n 'ADJUST_CORRECT': 74,\n 'INCLUDE-AS': 75,\n 'CONTINUE': 76,\n 'SPEED-UP': 77,\n 'LOAD_PROVIDE_CHARGE_FURNISH': 78,\n 'REMEMBER': 79,\n 'FINISH_CONCLUDE_END': 80,\n 'REPEAT': 81,\n 'HELP_HEAL_CARE_CURE': 82,\n 'IMPLY': 83,\n 'OPPOSE_REBEL_DISSENT': 84,\n 'STRENGTHEN_MAKE-RESISTANT': 85,\n 'AROUSE_WAKE_ENLIVEN': 86,\n 'RECORD': 87,\n 'INCITE_INDUCE': 88,\n 'GIVE_GIFT': 89,\n 'DESTROY': 90,\n 'REQUIRE_NEED_WANT_HOPE': 91,\n 'ANALYZE': 92,\n 'COME-AFTER_FOLLOW-IN-TIME': 93,\n 'BELIEVE': 94,\n 'GO-FORWARD': 95,\n 'CANCEL_ELIMINATE': 96,\n 'RECOGNIZE_ADMIT_IDENTIFY': 97,\n 'CHOOSE': 98,\n 'REPRESENT': 99,\n 'TREAT': 100,\n 'OBLIGE_FORCE': 101,\n 'STOP': 102,\n 'REACT': 103,\n 'HAPPEN_OCCUR': 104,\n 'OVERCOME_SURPASS': 105,\n 'AFFECT': 106,\n 'CREATE_MATERIALIZE': 107,\n 'ALLY_ASSOCIATE_MARRY': 108,\n 'MANAGE': 109,\n 'OPEN': 110,\n 'ORIENT': 111,\n 'ANSWER': 112,\n 'INFLUENCE': 113,\n 'COMBINE_MIX_UNITE': 114,\n 'LEAD_GOVERN': 115,\n 'STAY_DWELL': 116,\n 'WELCOME': 117,\n 'AMASS': 118,\n 'PREPARE': 119,\n 'ORGANIZE': 120,\n 'HAVE-A-FUNCTION_SERVE': 121,\n 'GIVE-UP_ABOLISH_ABANDON': 122,\n 'SORT_CLASSIFY_ARRANGE': 123,\n 'GIVE-BIRTH': 124,\n 'PUBLISH': 125,\n 'USE': 126,\n 'POSSESS': 127,\n 'BEHAVE': 128,\n 'WORK': 129,\n 'SUBJECTIVE-JUDGING': 130,\n 'APPROVE_PRAISE': 131,\n 'ATTEND': 132,\n 'LEAVE_DEPART_RUN-AWAY': 133,\n 'CATCH': 134,\n 'OBEY': 135,\n 'SATISFY_FULFILL': 136,\n 'UNDERSTAND': 137,\n 'ACHIEVE': 138,\n 'TRY': 139,\n 'ATTACH': 140,\n 'INTERPRET': 141,\n 'DELAY': 142,\n 'REDUCE_DIMINISH': 143,\n 'UNDERGO-EXPERIENCE': 144,\n 'RETAIN_KEEP_SAVE-MONEY': 145,\n 'ARRIVE': 146,\n 'REFUSE': 147,\n 'IMAGINE': 148,\n 'HARMONIZE': 149,\n 'PARTICIPATE': 150,\n 'HIRE': 151,\n 'RESULT_CONSEQUENCE': 152,\n 'FOCUS': 153,\n 'CONTAIN': 154,\n 'MOUNT_ASSEMBLE_PRODUCE': 155,\n 'PROVE': 156,\n 'WRITE': 157,\n 'RESTRAIN': 158,\n 'TOLERATE': 159,\n 'ACCOMPANY': 160,\n 'DISCUSS': 161,\n 'RESTORE-TO-PREVIOUS/INITIAL-STATE_UNDO_UNWIND': 162,\n 'TEACH': 163,\n 'CHANGE-APPEARANCE/STATE': 164,\n 'INVERT_REVERSE': 165,\n 'RELY': 166,\n 'SIGNAL_INDICATE': 167,\n 'LEARN': 168,\n 'ACCUSE': 169,\n 'PERFORM': 170,\n 'AFFIRM': 171,\n 'REMOVE_TAKE-AWAY_KIDNAP': 172,\n 'WATCH_LOOK-OUT': 173,\n 'GROUND_BASE_FOUND': 174,\n 'LEAVE-BEHIND': 175,\n 'FACE_CHALLENGE': 176,\n 'CHANGE_SWITCH': 177,\n 'SHARE': 178,\n 'APPLY': 179,\n 'ARGUE-IN-DEFENSE': 180,\n 'DIRECT_AIM_MANEUVER': 181,\n 'WAIT': 182,\n 'HEAR_LISTEN': 183,\n 'CONSIDER': 184,\n 'LIKE': 185,\n 'FIGHT': 186,\n 'PROTECT': 187,\n 'AUTHORIZE_ADMIT': 188,\n 'DIVERSIFY': 189,\n 'PRESERVE': 190,\n 'LOCATE-IN-TIME_DATE': 191,\n 'SEND': 192,\n 'ORDER': 193,\n 'SEARCH': 194,\n 'REGRET_SORRY': 195,\n 'EMPHASIZE': 196,\n 'CELEBRATE_PARTY': 197,\n 'TAKE-SHELTER': 198,\n 'HOST_MEAL_INVITE': 199,\n 'REPLACE': 200,\n 'THINK': 201,\n 'MEET': 202,\n 'PERCEIVE': 203,\n 'BREAK_DETERIORATE': 204,\n 'JOIN_CONNECT': 205,\n 'BORDER': 206,\n 'FIND': 207,\n 'KNOW': 208,\n 'KILL': 209,\n 'CHARGE': 210,\n 'FAIL_LOSE': 211,\n 'CRITICIZE': 212,\n 'CITE': 213,\n 'HIT': 214,\n 'LIBERATE_ALLOW_AFFORD': 215,\n 'BRING': 216,\n 'DERIVE': 217,\n 'JUSTIFY_EXCUSE': 218,\n 'PERSUADE': 219,\n 'REVEAL': 220,\n 'DRIVE-BACK': 221,\n 'TAKE': 222,\n 'OBTAIN': 223,\n 'LOSE': 224,\n 'ADD': 225,\n 'MATCH': 226,\n 'CONSUME_SPEND': 227,\n 'COMPARE': 228,\n 'BEFRIEND': 229,\n 'NAME': 230,\n 'BE-LOCATED_BASE': 231,\n 'OFFER': 232,\n 'OVERLAP': 233,\n 'CARRY_TRANSPORT': 234,\n 'REACH': 235,\n 'FILL': 236,\n 'ENCLOSE_WRAP': 237,\n 'DISBAND_BREAK-UP': 238,\n 'COUNT': 239,\n 'DEFEAT': 240,\n 'CO-OPT': 241,\n 'ENDANGER': 242,\n 'PUNISH': 243,\n 'TRANSLATE': 244,\n 'SECURE_FASTEN_TIE': 245,\n 'INSERT': 246,\n 'REMAIN': 247,\n 'BUY': 248,\n 'STEAL_DEPRIVE': 249,\n 'SETTLE_CONCILIATE': 250,\n 'EXTEND': 251,\n 'SUMMARIZE': 252,\n 'PUBLICIZE': 253,\n 'CORRELATE': 254,\n 'SEPARATE_FILTER_DETACH': 255,\n 'GROUP': 256,\n 'COST': 257,\n 'ATTACK_BOMB': 258,\n 'WARN': 259,\n 'NEGOTIATE': 260,\n 'ENTER': 261,\n 'LIE': 262,\n 'SPEND-TIME_PASS-TIME': 263,\n 'EMPTY_UNLOAD': 264,\n 'INVERT_REVERSE-': 265,\n 'EMIT': 266,\n 'TURN_CHANGE-DIRECTION': 267,\n 'SELL': 268,\n 'GUESS': 269,\n 'DISCARD': 270,\n 'CONTRACT-AN-ILLNESS_INFECT': 271,\n 'WASH_CLEAN': 272,\n 'DROP': 273,\n 'OPERATE': 274,\n 'SHARPEN': 275,\n 'REFLECT': 276,\n 'COMPENSATE': 277,\n 'ASCRIBE': 278,\n 'LOWER': 279,\n 'COPY': 280,\n 'DEBASE_ADULTERATE': 281,\n 'DISMISS_FIRE-SMN': 282,\n 'COVER_SPREAD_SURMOUNT': 283,\n 'MEASURE_EVALUATE': 284,\n 'RESIGN_RETIRE': 285,\n 'READ': 286,\n 'DISTINGUISH_DIFFER': 287,\n 'TRAVEL': 288,\n 'RESIST': 289,\n 'SHOOT_LAUNCH_PROPEL': 290,\n 'BURDEN_BEAR': 291,\n 'SOLVE': 292,\n 'WIN': 293,\n 'APPEAR': 294,\n 'FOLLOW-IN-SPACE': 295,\n 'PULL': 296,\n 'PAINT': 297,\n 'COME-FROM': 298,\n 'VISIT': 299,\n 'COOL': 300,\n 'DOWNPLAY_HUMILIATE': 301,\n 'CHASE': 302,\n 'EMBELLISH': 303,\n 'EARN': 304,\n 'RAISE': 305,\n 'PROMOTE': 306,\n 'MEAN': 307,\n 'EXHAUST': 308,\n 'ABSORB': 309,\n 'PRESS_PUSH_FOLD': 310,\n 'LEND': 311,\n 'SHAPE': 312,\n 'PRINT': 313,\n 'REPAIR_REMEDY': 314,\n 'GROW_PLOW': 315,\n 'QUARREL_POLEMICIZE': 316,\n 'TAKE-A-SERVICE_RENT': 317,\n 'COMPETE': 318,\n 'DIVIDE': 319,\n 'COMMUNICATE_CONTACT': 320,\n 'FIT': 321,\n 'EXEMPT': 322,\n 'SLOW-DOWN': 323,\n 'FLOW': 324,\n 'RISK': 325,\n 'METEOROLOGICAL': 326,\n 'NOURISH_FEED': 327,\n 'STABILIZE_SUPPORT-PHYSICALLY': 328}"},"metadata":{}}]},{"cell_type":"code","source":"train, val = train_test_split(data, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:37.993941Z","iopub.execute_input":"2023-02-03T00:48:37.994286Z","iopub.status.idle":"2023-02-03T00:48:38.042781Z","shell.execute_reply.started":"2023-02-03T00:48:37.994249Z","shell.execute_reply":"2023-02-03T00:48:38.041847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_org=pd.read_json('/kaggle/input/data-srl-nlp-modified/data_hw2/data_hw2/EN/dev.json').transpose(copy=True)\ntest_org[\"index_predicate\"]=test_org['predicates'].apply(lambda x:separate_predicates(x))\ntest=test_org.explode('index_predicate')\ntest.dropna(inplace=True)\ntest['roles'] = test.apply(lambda x: get_dict(x['roles'], x['index_predicate']), axis=1)\ntest.dropna(inplace=True)\ntest['roles']=test.roles.apply(lambda x: role_label(x))\ntest['roles'] = test.apply(lambda x: add_predicate(x['roles'],x['predicates'], x['index_predicate']), axis=1)\ntest['pos_tags']=test.pos_tags.apply(lambda x: role_pos(x))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:38.046422Z","iopub.execute_input":"2023-02-03T00:48:38.046751Z","iopub.status.idle":"2023-02-03T00:48:38.689084Z","shell.execute_reply.started":"2023-02-03T00:48:38.046726Z","shell.execute_reply":"2023-02-03T00:48:38.688103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fr_data=pd.read_json('/kaggle/input/data-srl-nlp-modified/data_hw2/data_hw2/FR/train.json').transpose(copy=True)\nfr_data[\"index_predicate\"]=fr_data['predicates'].apply(lambda x:separate_predicates(x))\nfr_data=fr_data.explode('index_predicate')\nfr_data.dropna(inplace=True)\nfr_data['roles'] = fr_data.apply(lambda x: get_dict(x['roles'], x['index_predicate']), axis=1)\nfr_data.dropna(inplace=True)\nfr_data['roles']=fr_data.roles.apply(lambda x: role_label(x))\nfr_data['roles'] = fr_data.apply(lambda x: add_predicate(x['roles'],x['predicates'], x['index_predicate']), axis=1)\nfr_data['pos_tags']=fr_data.pos_tags.apply(lambda x: role_pos(x))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:38.690540Z","iopub.execute_input":"2023-02-03T00:48:38.691125Z","iopub.status.idle":"2023-02-03T00:48:38.899538Z","shell.execute_reply.started":"2023-02-03T00:48:38.691080Z","shell.execute_reply":"2023-02-03T00:48:38.898604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fr_train, fr_val = train_test_split(fr_data, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:38.900894Z","iopub.execute_input":"2023-02-03T00:48:38.901336Z","iopub.status.idle":"2023-02-03T00:48:38.912325Z","shell.execute_reply.started":"2023-02-03T00:48:38.901301Z","shell.execute_reply":"2023-02-03T00:48:38.911327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fr_test=pd.read_json('/kaggle/input/data-srl-nlp-modified/data_hw2/data_hw2/FR/dev.json').transpose(copy=True)\nfr_test[\"index_predicate\"]=fr_test['predicates'].apply(lambda x:separate_predicates(x))\nfr_test=fr_test.explode('index_predicate')\nfr_test.dropna(inplace=True)\nfr_test['roles'] = fr_test.apply(lambda x: get_dict(x['roles'], x['index_predicate']), axis=1)\nfr_test.dropna(inplace=True)\nfr_test['roles']=fr_test.roles.apply(lambda x: role_label(x))\nfr_test['roles'] = fr_test.apply(lambda x: add_predicate(x['roles'],x['predicates'], x['index_predicate']), axis=1)\nfr_test['pos_tags']=fr_test.pos_tags.apply(lambda x: role_pos(x))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:38.913655Z","iopub.execute_input":"2023-02-03T00:48:38.914038Z","iopub.status.idle":"2023-02-03T00:48:39.328312Z","shell.execute_reply.started":"2023-02-03T00:48:38.914000Z","shell.execute_reply":"2023-02-03T00:48:39.327373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es_data=pd.read_json('/kaggle/input/data-srl-nlp-modified/data_hw2/data_hw2/ES/train.json').transpose(copy=True)\nes_data[\"index_predicate\"]=es_data['predicates'].apply(lambda x:separate_predicates(x))\nes_data=es_data.explode('index_predicate')\nes_data.dropna(inplace=True)\nes_data['roles'] = es_data.apply(lambda x: get_dict(x['roles'], x['index_predicate']), axis=1)\nes_data.dropna(inplace=True)\nes_data['roles']=es_data.roles.apply(lambda x: role_label(x))\nes_data['roles'] = es_data.apply(lambda x: add_predicate(x['roles'],x['predicates'], x['index_predicate']), axis=1)\nes_data['pos_tags']=es_data.pos_tags.apply(lambda x: role_pos(x))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:39.329591Z","iopub.execute_input":"2023-02-03T00:48:39.330527Z","iopub.status.idle":"2023-02-03T00:48:39.524229Z","shell.execute_reply.started":"2023-02-03T00:48:39.330491Z","shell.execute_reply":"2023-02-03T00:48:39.523240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es_train, es_val = train_test_split(es_data, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:39.529160Z","iopub.execute_input":"2023-02-03T00:48:39.529462Z","iopub.status.idle":"2023-02-03T00:48:39.539820Z","shell.execute_reply.started":"2023-02-03T00:48:39.529436Z","shell.execute_reply":"2023-02-03T00:48:39.538591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es_test=pd.read_json('/kaggle/input/data-srl-nlp-modified/data_hw2/data_hw2/ES/dev.json').transpose(copy=True)\nes_test[\"index_predicate\"]=es_test['predicates'].apply(lambda x:separate_predicates(x))\nes_test=es_test.explode('index_predicate')\nes_test.dropna(inplace=True)\nes_test['roles'] = es_test.apply(lambda x: get_dict(x['roles'], x['index_predicate']), axis=1)\nes_test.dropna(inplace=True)\nes_test['roles']=es_test.roles.apply(lambda x: role_label(x))\nes_test['roles'] = es_test.apply(lambda x: add_predicate(x['roles'],x['predicates'], x['index_predicate']), axis=1)\nes_test['pos_tags']=es_test.pos_tags.apply(lambda x: role_pos(x))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:39.541424Z","iopub.execute_input":"2023-02-03T00:48:39.542069Z","iopub.status.idle":"2023-02-03T00:48:40.043929Z","shell.execute_reply.started":"2023-02-03T00:48:39.542031Z","shell.execute_reply":"2023-02-03T00:48:40.042916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset=TranDataset(data)\nval_dataset=TranDataset(val)\ntest_dataset=TranDataset(test)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True,collate_fn=collate_fn)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False,collate_fn=collate_fn)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False,collate_fn=collate_fn)\n##########FRENCH#############\nfr_train_dataset=TranDataset(fr_data)\nfr_val_dataset=TranDataset(fr_val)\nfr_test_dataset=TranDataset(fr_test)\nfr_train_dataloader = torch.utils.data.DataLoader(fr_train_dataset, batch_size=64, shuffle=True,collate_fn=collate_fn)\nfr_val_dataloader = torch.utils.data.DataLoader(fr_val_dataset, batch_size=64, shuffle=False,collate_fn=collate_fn)\nfr_test_dataloader = torch.utils.data.DataLoader(fr_test_dataset, batch_size=64, shuffle=False,collate_fn=collate_fn)\n##########ESP#############\nes_train_dataset=TranDataset(es_data)\nes_val_dataset=TranDataset(es_val)\nes_test_dataset=TranDataset(es_test)\nes_train_dataloader = torch.utils.data.DataLoader(es_train_dataset, batch_size=64, shuffle=True,collate_fn=collate_fn)\nes_val_dataloader = torch.utils.data.DataLoader(es_val_dataset, batch_size=64, shuffle=False,collate_fn=collate_fn)\nes_test_dataloader = torch.utils.data.DataLoader(es_test_dataset, batch_size=64, shuffle=False,collate_fn=collate_fn)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:40.045712Z","iopub.execute_input":"2023-02-03T00:48:40.046476Z","iopub.status.idle":"2023-02-03T00:48:40.492388Z","shell.execute_reply.started":"2023-02-03T00:48:40.046437Z","shell.execute_reply":"2023-02-03T00:48:40.491421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing the input which goes into model visually\nkk=2\nfor i in train_dataloader:\n    print(i)\n    print(i.input_ids.shape)\n    print(i.labels.shape)\n    print(i.predicate_loc.shape)\n    print(i.pos_tag.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:40.493941Z","iopub.execute_input":"2023-02-03T00:48:40.494282Z","iopub.status.idle":"2023-02-03T00:48:40.539261Z","shell.execute_reply.started":"2023-02-03T00:48:40.494248Z","shell.execute_reply":"2023-02-03T00:48:40.538351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SRLModel(torch.nn.Module):\n    def __init__(self,num_labels: int, fine_tune_lm: bool = True, *args, **kwargs) -> None:\n        super().__init__()\n        self.num_labels = num_labels\n        # layers\n        self.transformer_model = AutoModel.from_pretrained('xlm-roberta-base', output_hidden_states=True)\n        if not fine_tune_lm:\n            for param in self.transformer_model.parameters():\n                param.requires_grad = False\n        self.dropout = torch.nn.Dropout(0.5)\n        self.lstm = torch.nn.LSTM(input_size=self.transformer_model.config.hidden_size+1+18, \n                            hidden_size=800, \n                            batch_first=True,\n                            bidirectional=True,\n                            num_layers=2,\n                            dropout=0.5\n                                 )\n        self.lstm_output_dim = 800 * 2\n        self.relu = torch.nn.ReLU()\n        self.fc1 = torch.nn.Linear(self.lstm_output_dim, 512)\n        self.classifier = torch.nn.Linear(512, num_labels)\n        \n\n    def forward(self, batch):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask=batch['attention_mask'].to(device)\n        predicate_loc = batch['predicate_loc'].to(device)\n        pos_tags = batch['pos_tag'].to(device)\n        transformers_outputs = self.transformer_model(input_ids,attention_mask)\n        embed_out = torch.stack(transformers_outputs.hidden_states[-4:], dim=0).sum(dim=0)\n        concat_predicate_loc=torch.cat((embed_out,pos_tags,predicate_loc), 2)\n        output,_ = self.lstm(concat_predicate_loc)\n        fc1 = self.fc1(self.dropout(output))\n        fc1=self.relu(fc1)\n        preds = self.classifier(self.dropout(fc1))\n        return preds","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:40.540548Z","iopub.execute_input":"2023-02-03T00:48:40.540871Z","iopub.status.idle":"2023-02-03T00:48:40.551629Z","shell.execute_reply.started":"2023-02-03T00:48:40.540845Z","shell.execute_reply":"2023-02-03T00:48:40.550574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pre_trained_transformer_model = AutoModel.from_pretrained(language_model_name, output_hidden_states=True)\n# model=SRLModel(len(label_to_id),fine_tune_lm=False).to(device)\n# optimizer = torch.optim.Adam(model.parameters())\n# criterion = torch.nn.CrossEntropyLoss(ignore_index = -100)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:40.553236Z","iopub.execute_input":"2023-02-03T00:48:40.553943Z","iopub.status.idle":"2023-02-03T00:48:40.563928Z","shell.execute_reply.started":"2023-02-03T00:48:40.553883Z","shell.execute_reply":"2023-02-03T00:48:40.563132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, iterator, optimizer, criterion):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.train()\n    \n    for batch in tqdm(iterator):\n        \n        text = batch\n        tags = batch['labels']\n        \n        optimizer.zero_grad()\n        \n        #text = [sent len, batch size]\n        \n        predictions = model(text)\n        \n        #predictions = [sent len, batch size, output dim]\n        #tags = [sent len, batch size]\n        \n        predictions = predictions.view(-1, predictions.shape[-1])\n        tags = tags.view(-1).type(torch.LongTensor).to(device)\n        #predictions = [sent len * batch size, output dim]\n        #tags = [sent len * batch size]\n        \n        loss = criterion(predictions, tags)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        \n        \n    return epoch_loss / len(iterator)\n\ndef evaluate(model, iterator, criterion):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n    \n        for batch in iterator:\n\n            text = batch\n            tags = batch['labels']\n            \n            predictions = model(text)\n            \n            predictions = predictions.view(-1, predictions.shape[-1])\n            tags = tags.view(-1).type(torch.LongTensor).to(device)\n            \n\n            \n            loss = criterion(predictions, tags)\n            \n            epoch_loss += loss.item()\n        \n    return epoch_loss / len(iterator)\n\ndef predict(model, iterator):\n    pred=[]\n    tag=[]\n    model.eval()\n    \n    with torch.no_grad():\n        for batch in iterator:\n\n            text = batch\n            tags = batch['labels']\n            \n            predictions = model(text)\n            \n            predictions = predictions.view(-1, predictions.shape[-1])\n            max_preds = predictions.argmax(dim = 1, keepdim = False)\n            tags = tags.view(-1)\n\n            pred.append(max_preds.tolist())\n            tag.append(tags.tolist())\n            \n        \n    return pred,tag\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:48:40.567328Z","iopub.execute_input":"2023-02-03T00:48:40.567585Z","iopub.status.idle":"2023-02-03T00:48:40.582006Z","shell.execute_reply.started":"2023-02-03T00:48:40.567561Z","shell.execute_reply":"2023-02-03T00:48:40.580959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # load pretrained model\nload_pretrained_model=True\nif load_pretrained_model==True:\n    model_english = SRLModel(len(label_to_id),fine_tune_lm=False).to(device)\n    model_english.load_state_dict(torch.load('/kaggle/working/final_eng_hw2_234.pt', map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n    optimizer = torch.optim.Adam(model_english.parameters())\n    criterion = torch.nn.CrossEntropyLoss(ignore_index = -100)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T04:02:45.881256Z","iopub.execute_input":"2023-02-03T04:02:45.881657Z","iopub.status.idle":"2023-02-03T04:02:51.408321Z","shell.execute_reply.started":"2023-02-03T04:02:45.881625Z","shell.execute_reply":"2023-02-03T04:02:51.407268Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"N_EPOCHS =10\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n\n    start_time = time.time()\n    \n    train_loss= train_model(model_english, train_dataloader, optimizer, criterion)\n    valid_loss= evaluate(model_english, test_dataloader, criterion)\n    \n    end_time = time.time()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'modelhw2v1-model.pt')\n    \n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f}')\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:56:33.327070Z","iopub.execute_input":"2023-02-03T00:56:33.327417Z","iopub.status.idle":"2023-02-03T00:59:14.787793Z","shell.execute_reply.started":"2023-02-03T00:56:33.327388Z","shell.execute_reply":"2023-02-03T00:59:14.786300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test on test dataset for either all arguments\npred,label=predict(model_english,fr_test_dataloader)\npred = [item for sublist in pred for item in sublist]\nlabel = [item for sublist in label for item in sublist]\n# modify to get a range\n# get resulst only for predicate\nall_labels = list(label_to_id.values())\nexclude = [i for i in range(0,27)]\n# eval_args = [label for label in all_labels if label not in exclude]\n# get resulst only for arguments\neval_args=list(itemgetter('agent', 'theme', 'beneficiary', 'patient', 'topic', 'goal', 'recipient', \n                 'co-theme', 'result', 'stimulus', 'experiencer', 'destination', 'value', \n                 'attribute', 'location', 'source', 'cause', 'co-agent', 'time', 'co-patient',\n                 'product', 'purpose', 'instrument', 'extent', 'asset', 'material')(label_to_id))\nf1_score(label,pred,labels=eval_args,average='micro')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T01:04:56.526905Z","iopub.execute_input":"2023-02-03T01:04:56.527261Z","iopub.status.idle":"2023-02-03T01:05:10.791368Z","shell.execute_reply.started":"2023-02-03T01:04:56.527232Z","shell.execute_reply":"2023-02-03T01:05:10.790225Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"0.5875091366848046"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model_english.state_dict(), 'final_fr_hw2_234.pt')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:51:01.452051Z","iopub.execute_input":"2023-02-03T00:51:01.452642Z","iopub.status.idle":"2023-02-03T00:51:04.872697Z","shell.execute_reply.started":"2023-02-03T00:51:01.452604Z","shell.execute_reply":"2023-02-03T00:51:04.871230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine Tune on French and Spanish","metadata":{}},{"cell_type":"code","source":"class Identity(torch.nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n        \n    def forward(self, x):\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-02-03T01:36:05.175349Z","iopub.execute_input":"2023-02-03T01:36:05.175739Z","iopub.status.idle":"2023-02-03T01:36:05.181426Z","shell.execute_reply.started":"2023-02-03T01:36:05.175703Z","shell.execute_reply":"2023-02-03T01:36:05.180274Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"class SRLModelEsp(torch.nn.Module):\n    def __init__(self, base_model, num_labels: int, *args, **kwargs):\n        super().__init__()\n        self.base_model = base_model\n        self.base_model.classifier=Identity()\n#         freeze the base model\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n        self.num_labels = num_labels\n        self.classifier_es = torch.nn.Linear(512, num_labels)\n        \n    def forward(self, batch):\n        preds = self.base_model(batch)\n        preds = self.classifier_es(preds)\n        return preds\n\nSRL_model_es = SRLModelEsp(model_english, len(label_to_id)).to(device)\noptimizer = torch.optim.Adam(SRL_model_es.parameters())\ncriterion = torch.nn.CrossEntropyLoss(ignore_index = -100)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T01:53:32.736609Z","iopub.execute_input":"2023-02-03T01:53:32.737609Z","iopub.status.idle":"2023-02-03T01:53:32.755212Z","shell.execute_reply.started":"2023-02-03T01:53:32.737571Z","shell.execute_reply":"2023-02-03T01:53:32.754142Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 10\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n\n    start_time = time.time()\n    \n    train_loss= train_model(SRL_model_es, es_train_dataloader, optimizer, criterion)\n    valid_loss= evaluate(SRL_model_es, es_val_dataloader, criterion)\n    \n    end_time = time.time()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(SRL_model_french.state_dict(), 'modelhw2v1_fr-model.pt')\n    \n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test on test dataset for either all arguments\npred,label=predict(SRL_model_es,es_test_dataloader)\npred = [item for sublist in pred for item in sublist]\nlabel = [item for sublist in label for item in sublist]\n# modify to get a range\n# get resulst only for predicate\nall_labels = list(label_to_id.values())\n# exclude = [i for i in range(0,27)]\n# eval_args = [label for label in all_labels if label not in exclude]\n# get resulst only for arguments\neval_args=list(itemgetter('agent', 'theme', 'beneficiary', 'patient', 'topic', 'goal', 'recipient', \n                 'co-theme', 'result', 'stimulus', 'experiencer', 'destination', 'value', \n                 'attribute', 'location', 'source', 'cause', 'co-agent', 'time', 'co-patient',\n                 'product', 'purpose', 'instrument', 'extent', 'asset', 'material')(label_to_id))\nf1_score(label,pred,labels=eval_args,average='micro')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T02:14:26.779509Z","iopub.execute_input":"2023-02-03T02:14:26.779926Z","iopub.status.idle":"2023-02-03T02:14:39.416557Z","shell.execute_reply.started":"2023-02-03T02:14:26.779889Z","shell.execute_reply":"2023-02-03T02:14:39.415578Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"0.6287413660782809"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(SRL_model_es.state_dict(), 'final_es_hw_234.pt')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T02:14:47.812470Z","iopub.execute_input":"2023-02-03T02:14:47.812843Z","iopub.status.idle":"2023-02-03T02:14:51.148110Z","shell.execute_reply.started":"2023-02-03T02:14:47.812808Z","shell.execute_reply":"2023-02-03T02:14:51.146759Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"class SRLModelFrench(torch.nn.Module):\n    def __init__(self, base_model, num_labels: int, *args, **kwargs):\n        super().__init__()\n        self.base_model = base_model\n        self.base_model.classifier=Identity()\n#         freeze the base model\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n        self.num_labels = num_labels\n        self.classifier_fr = torch.nn.Linear(512, num_labels)\n        \n    def forward(self, batch):\n        preds = self.base_model(batch)\n        preds = self.classifier_fr(preds)\n        return preds\n\nSRL_model_french = SRLModelFrench(model_english, len(label_to_id)).to(device)\noptimizer = torch.optim.Adam(SRL_model_french.parameters())\ncriterion = torch.nn.CrossEntropyLoss(ignore_index = -100)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T04:03:00.681514Z","iopub.execute_input":"2023-02-03T04:03:00.681892Z","iopub.status.idle":"2023-02-03T04:03:00.698940Z","shell.execute_reply.started":"2023-02-03T04:03:00.681861Z","shell.execute_reply":"2023-02-03T04:03:00.697911Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 100\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n\n    start_time = time.time()\n    \n    train_loss= train_model(SRL_model_french, fr_train_dataloader, optimizer, criterion)\n    valid_loss= evaluate(SRL_model_french, fr_val_dataloader, criterion)\n    \n    end_time = time.time()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(SRL_model_french.state_dict(), 'modelhw2v1_fr-model.pt')\n    \n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T04:03:03.361016Z","iopub.execute_input":"2023-02-03T04:03:03.361400Z","iopub.status.idle":"2023-02-03T04:17:08.748503Z","shell.execute_reply.started":"2023-02-03T04:03:03.361369Z","shell.execute_reply":"2023-02-03T04:17:08.747314Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 01 | Epoch Time: 0m 8s\n\tTrain Loss: 2.573\n\t Val. Loss: 0.346\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 02 | Epoch Time: 0m 8s\n\tTrain Loss: 0.336\n\t Val. Loss: 0.262\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 03 | Epoch Time: 0m 8s\n\tTrain Loss: 0.282\n\t Val. Loss: 0.228\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 04 | Epoch Time: 0m 8s\n\tTrain Loss: 0.257\n\t Val. Loss: 0.209\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 05 | Epoch Time: 0m 8s\n\tTrain Loss: 0.241\n\t Val. Loss: 0.196\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 06 | Epoch Time: 0m 8s\n\tTrain Loss: 0.231\n\t Val. Loss: 0.187\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 07 | Epoch Time: 0m 8s\n\tTrain Loss: 0.225\n\t Val. Loss: 0.180\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 08 | Epoch Time: 0m 8s\n\tTrain Loss: 0.215\n\t Val. Loss: 0.175\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 09 | Epoch Time: 0m 8s\n\tTrain Loss: 0.213\n\t Val. Loss: 0.170\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10 | Epoch Time: 0m 8s\n\tTrain Loss: 0.207\n\t Val. Loss: 0.166\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11 | Epoch Time: 0m 8s\n\tTrain Loss: 0.204\n\t Val. Loss: 0.163\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12 | Epoch Time: 0m 8s\n\tTrain Loss: 0.199\n\t Val. Loss: 0.160\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 13 | Epoch Time: 0m 8s\n\tTrain Loss: 0.194\n\t Val. Loss: 0.157\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 14 | Epoch Time: 0m 8s\n\tTrain Loss: 0.193\n\t Val. Loss: 0.154\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 15 | Epoch Time: 0m 8s\n\tTrain Loss: 0.190\n\t Val. Loss: 0.153\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 16 | Epoch Time: 0m 8s\n\tTrain Loss: 0.188\n\t Val. Loss: 0.151\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 17 | Epoch Time: 0m 8s\n\tTrain Loss: 0.188\n\t Val. Loss: 0.149\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 18 | Epoch Time: 0m 8s\n\tTrain Loss: 0.184\n\t Val. Loss: 0.147\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 19 | Epoch Time: 0m 8s\n\tTrain Loss: 0.181\n\t Val. Loss: 0.146\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 20 | Epoch Time: 0m 8s\n\tTrain Loss: 0.180\n\t Val. Loss: 0.145\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 21 | Epoch Time: 0m 8s\n\tTrain Loss: 0.179\n\t Val. Loss: 0.143\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 22 | Epoch Time: 0m 8s\n\tTrain Loss: 0.177\n\t Val. Loss: 0.142\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 23 | Epoch Time: 0m 8s\n\tTrain Loss: 0.176\n\t Val. Loss: 0.141\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 24 | Epoch Time: 0m 8s\n\tTrain Loss: 0.176\n\t Val. Loss: 0.140\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 25 | Epoch Time: 0m 8s\n\tTrain Loss: 0.175\n\t Val. Loss: 0.139\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 26 | Epoch Time: 0m 8s\n\tTrain Loss: 0.174\n\t Val. Loss: 0.138\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 27 | Epoch Time: 0m 8s\n\tTrain Loss: 0.174\n\t Val. Loss: 0.137\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 28 | Epoch Time: 0m 8s\n\tTrain Loss: 0.172\n\t Val. Loss: 0.136\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 29 | Epoch Time: 0m 8s\n\tTrain Loss: 0.173\n\t Val. Loss: 0.135\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 30 | Epoch Time: 0m 8s\n\tTrain Loss: 0.172\n\t Val. Loss: 0.135\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 31 | Epoch Time: 0m 8s\n\tTrain Loss: 0.170\n\t Val. Loss: 0.133\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 32 | Epoch Time: 0m 8s\n\tTrain Loss: 0.168\n\t Val. Loss: 0.133\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 33 | Epoch Time: 0m 8s\n\tTrain Loss: 0.168\n\t Val. Loss: 0.132\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 34 | Epoch Time: 0m 8s\n\tTrain Loss: 0.168\n\t Val. Loss: 0.132\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 35 | Epoch Time: 0m 8s\n\tTrain Loss: 0.167\n\t Val. Loss: 0.130\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 36 | Epoch Time: 0m 8s\n\tTrain Loss: 0.167\n\t Val. Loss: 0.130\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 37 | Epoch Time: 0m 8s\n\tTrain Loss: 0.163\n\t Val. Loss: 0.130\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 38 | Epoch Time: 0m 8s\n\tTrain Loss: 0.169\n\t Val. Loss: 0.129\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 39 | Epoch Time: 0m 8s\n\tTrain Loss: 0.165\n\t Val. Loss: 0.129\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 40 | Epoch Time: 0m 8s\n\tTrain Loss: 0.167\n\t Val. Loss: 0.128\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 41 | Epoch Time: 0m 8s\n\tTrain Loss: 0.164\n\t Val. Loss: 0.128\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 42 | Epoch Time: 0m 8s\n\tTrain Loss: 0.165\n\t Val. Loss: 0.127\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 43 | Epoch Time: 0m 8s\n\tTrain Loss: 0.161\n\t Val. Loss: 0.127\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 44 | Epoch Time: 0m 8s\n\tTrain Loss: 0.162\n\t Val. Loss: 0.126\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 45 | Epoch Time: 0m 8s\n\tTrain Loss: 0.160\n\t Val. Loss: 0.126\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 46 | Epoch Time: 0m 8s\n\tTrain Loss: 0.159\n\t Val. Loss: 0.126\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 47 | Epoch Time: 0m 8s\n\tTrain Loss: 0.163\n\t Val. Loss: 0.125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 48 | Epoch Time: 0m 8s\n\tTrain Loss: 0.160\n\t Val. Loss: 0.125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 49 | Epoch Time: 0m 8s\n\tTrain Loss: 0.162\n\t Val. Loss: 0.124\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 50 | Epoch Time: 0m 8s\n\tTrain Loss: 0.160\n\t Val. Loss: 0.124\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 51 | Epoch Time: 0m 8s\n\tTrain Loss: 0.160\n\t Val. Loss: 0.124\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 52 | Epoch Time: 0m 8s\n\tTrain Loss: 0.161\n\t Val. Loss: 0.123\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 53 | Epoch Time: 0m 8s\n\tTrain Loss: 0.162\n\t Val. Loss: 0.123\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 54 | Epoch Time: 0m 8s\n\tTrain Loss: 0.159\n\t Val. Loss: 0.122\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 55 | Epoch Time: 0m 8s\n\tTrain Loss: 0.157\n\t Val. Loss: 0.122\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 56 | Epoch Time: 0m 8s\n\tTrain Loss: 0.159\n\t Val. Loss: 0.121\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 57 | Epoch Time: 0m 8s\n\tTrain Loss: 0.158\n\t Val. Loss: 0.121\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 58 | Epoch Time: 0m 8s\n\tTrain Loss: 0.157\n\t Val. Loss: 0.121\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 59 | Epoch Time: 0m 8s\n\tTrain Loss: 0.158\n\t Val. Loss: 0.120\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 60 | Epoch Time: 0m 8s\n\tTrain Loss: 0.159\n\t Val. Loss: 0.120\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 61 | Epoch Time: 0m 8s\n\tTrain Loss: 0.158\n\t Val. Loss: 0.120\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 62 | Epoch Time: 0m 8s\n\tTrain Loss: 0.156\n\t Val. Loss: 0.119\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 63 | Epoch Time: 0m 8s\n\tTrain Loss: 0.156\n\t Val. Loss: 0.119\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 64 | Epoch Time: 0m 8s\n\tTrain Loss: 0.159\n\t Val. Loss: 0.119\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 65 | Epoch Time: 0m 8s\n\tTrain Loss: 0.157\n\t Val. Loss: 0.119\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 66 | Epoch Time: 0m 8s\n\tTrain Loss: 0.156\n\t Val. Loss: 0.118\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 67 | Epoch Time: 0m 8s\n\tTrain Loss: 0.157\n\t Val. Loss: 0.118\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 68 | Epoch Time: 0m 8s\n\tTrain Loss: 0.154\n\t Val. Loss: 0.119\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 69 | Epoch Time: 0m 8s\n\tTrain Loss: 0.156\n\t Val. Loss: 0.118\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 70 | Epoch Time: 0m 8s\n\tTrain Loss: 0.155\n\t Val. Loss: 0.117\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 71 | Epoch Time: 0m 8s\n\tTrain Loss: 0.155\n\t Val. Loss: 0.118\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 72 | Epoch Time: 0m 8s\n\tTrain Loss: 0.155\n\t Val. Loss: 0.118\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 73 | Epoch Time: 0m 8s\n\tTrain Loss: 0.156\n\t Val. Loss: 0.117\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 74 | Epoch Time: 0m 8s\n\tTrain Loss: 0.156\n\t Val. Loss: 0.117\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 75 | Epoch Time: 0m 8s\n\tTrain Loss: 0.154\n\t Val. Loss: 0.116\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 76 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.116\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 77 | Epoch Time: 0m 8s\n\tTrain Loss: 0.155\n\t Val. Loss: 0.116\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 78 | Epoch Time: 0m 8s\n\tTrain Loss: 0.154\n\t Val. Loss: 0.115\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 79 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.116\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 80 | Epoch Time: 0m 8s\n\tTrain Loss: 0.152\n\t Val. Loss: 0.116\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 81 | Epoch Time: 0m 8s\n\tTrain Loss: 0.154\n\t Val. Loss: 0.116\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 82 | Epoch Time: 0m 8s\n\tTrain Loss: 0.154\n\t Val. Loss: 0.116\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 83 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.115\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 84 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.115\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 85 | Epoch Time: 0m 8s\n\tTrain Loss: 0.152\n\t Val. Loss: 0.115\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 86 | Epoch Time: 0m 8s\n\tTrain Loss: 0.152\n\t Val. Loss: 0.114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 87 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.115\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 88 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.115\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 89 | Epoch Time: 0m 8s\n\tTrain Loss: 0.151\n\t Val. Loss: 0.114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 90 | Epoch Time: 0m 8s\n\tTrain Loss: 0.150\n\t Val. Loss: 0.114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 91 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 92 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 93 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 94 | Epoch Time: 0m 8s\n\tTrain Loss: 0.152\n\t Val. Loss: 0.114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 95 | Epoch Time: 0m 8s\n\tTrain Loss: 0.150\n\t Val. Loss: 0.114\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 96 | Epoch Time: 0m 8s\n\tTrain Loss: 0.152\n\t Val. Loss: 0.113\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 97 | Epoch Time: 0m 8s\n\tTrain Loss: 0.151\n\t Val. Loss: 0.113\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:06<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 98 | Epoch Time: 0m 8s\n\tTrain Loss: 0.149\n\t Val. Loss: 0.113\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 99 | Epoch Time: 0m 8s\n\tTrain Loss: 0.153\n\t Val. Loss: 0.113\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:07<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 100 | Epoch Time: 0m 8s\n\tTrain Loss: 0.151\n\t Val. Loss: 0.113\n","output_type":"stream"}]},{"cell_type":"code","source":"#test on test dataset for either all arguments\npred,label=predict(SRL_model_french,fr_test_dataloader)\npred = [item for sublist in pred for item in sublist]\nlabel = [item for sublist in label for item in sublist]\n# modify to get a range\n# get resulst only for predicate\n# all_labels = list(label_to_id.values())\n# exclude = [i for i in range(0,27)]\n# eval_args = [label for label in all_labels if label not in exclude]\n# get resulst only for arguments\neval_args=list(itemgetter('agent', 'theme', 'beneficiary', 'patient', 'topic', 'goal', 'recipient', \n                 'co-theme', 'result', 'stimulus', 'experiencer', 'destination', 'value', \n                 'attribute', 'location', 'source', 'cause', 'co-agent', 'time', 'co-patient',\n                 'product', 'purpose', 'instrument', 'extent', 'asset', 'material')(label_to_id))\nf1_score(label,pred,labels=eval_args,average='micro')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T04:20:24.125847Z","iopub.execute_input":"2023-02-03T04:20:24.126253Z","iopub.status.idle":"2023-02-03T04:20:38.122191Z","shell.execute_reply.started":"2023-02-03T04:20:24.126223Z","shell.execute_reply":"2023-02-03T04:20:38.121209Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0.6103439403036282"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(SRL_model_french.state_dict(), 'final_fr_hw_234_final.pt')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T04:20:40.082216Z","iopub.execute_input":"2023-02-03T04:20:40.083463Z","iopub.status.idle":"2023-02-03T04:20:43.700071Z","shell.execute_reply.started":"2023-02-03T04:20:40.083402Z","shell.execute_reply":"2023-02-03T04:20:43.698602Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#train- english /en-es/ en-fr\n#EN-80-76-76\n#ES-59-70-66\n#FR-60-63-67.7","metadata":{"execution":{"iopub.status.busy":"2023-02-03T00:54:00.844597Z","iopub.execute_input":"2023-02-03T00:54:00.848740Z","iopub.status.idle":"2023-02-03T00:54:00.855935Z","shell.execute_reply.started":"2023-02-03T00:54:00.848660Z","shell.execute_reply":"2023-02-03T00:54:00.855032Z"},"trusted":true},"execution_count":null,"outputs":[]}]}